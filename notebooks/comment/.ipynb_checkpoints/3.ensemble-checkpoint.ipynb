{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Any\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from deeppavlov.core.common.registry import register\n",
    "from deeppavlov.core.common.log import get_logger\n",
    "from deeppavlov.core.models.component import Component\n",
    "from utils import flatten_nested_list\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@register(\"ensemble_ranker\")\n",
    "class EnsembleRanker(Component):\n",
    "\n",
    "    def __init__(self, top_n=10, active=True, *args, **kwargs):\n",
    "        self.top_n = top_n\n",
    "        self.active = active\n",
    "\n",
    "    def __call__(self, tfidf: List[List[List[Union[Any]]]] = None,\n",
    "                 tfhub: List[List[List[Union[Any]]]] = None,\n",
    "                 rnet: List[List[List[Union[Any]]]] = None, *args, **kwargs) -> \\\n",
    "            List[List[List[Union[str, int, float]]]]:\n",
    "\n",
    "        CHUNK_IDX = 3\n",
    "        SCORE_IDX = 2\n",
    "        FAKE_SCORE = 0.001\n",
    "        NORM_THRESH = 50  # take only the first 50 results to count np.linalg.norm?\n",
    "\n",
    "        if tfidf is not None:\n",
    "            tfidf = [[list(el) for el in instance] for instance in tfidf]  # instance is a batch of results given a query\n",
    "        if rnet is not None:\n",
    "            rnet = [[list(el) for el in instance] for instance in rnet]\n",
    "        if tfhub is not None:\n",
    "            tfhub = [[list(el) for el in instance] for instance in tfhub]\n",
    "\n",
    "        rankers = [r for r in [tfidf, tfhub, rnet] if r is not None]\n",
    "        num_rankers = len(rankers)\n",
    "\n",
    "        def update_all_predictions(predictions, ranker_instance):\n",
    "            for predicted_chunk in ranker_instance:\n",
    "                chunk_idx = predicted_chunk[CHUNK_IDX]\n",
    "                if chunk_idx in instance_data_ids:\n",
    "                    data_idx = list(map(itemgetter(CHUNK_IDX), predictions)).index(chunk_idx)\n",
    "                    predictions[data_idx][SCORE_IDX] = flatten_nested_list(\n",
    "                        predictions[data_idx][SCORE_IDX] + [predicted_chunk[SCORE_IDX]])\n",
    "                else:\n",
    "                    predicted_chunk[SCORE_IDX] = [predicted_chunk[SCORE_IDX]]\n",
    "                    predictions.append(predicted_chunk)\n",
    "\n",
    "        def normalize_scores(ranker_results):\n",
    "            \"\"\"\n",
    "            Normalize paragraph scores with np.linalg.norm(L2) for each batch\n",
    "            \"\"\"\n",
    "            for instance in ranker_results:\n",
    "                scores = list(map(itemgetter(SCORE_IDX), instance))\n",
    "                norm = np.linalg.norm(scores[:NORM_THRESH])\n",
    "                for pred in instance:\n",
    "                    pred[SCORE_IDX] = float(pred[SCORE_IDX] / norm)\n",
    "\n",
    "        # Normalize scores from all tfidf and rnet:\n",
    "        if tfidf is not None:\n",
    "            normalize_scores(tfidf)\n",
    "        if rnet is not None:\n",
    "            normalize_scores(rnet)\n",
    "\n",
    "        # Count average scores from all rankers\n",
    "        all_data = []\n",
    "        for instances in zip(*rankers):\n",
    "            print('1:', instances, '\\n')\n",
    "            for item in instances[0]:\n",
    "                item[SCORE_IDX] = [item[SCORE_IDX]]\n",
    "            print('2:', instances, '\\n')\n",
    "\n",
    "            instance_predictions = copy.deepcopy(instances[0]); print('ins pred:', instance_predictions, '\\n')\n",
    "            instance_data_ids = set(map(itemgetter(CHUNK_IDX), instance_predictions))\n",
    "\n",
    "            for i in range(1, len(instances)):\n",
    "                update_all_predictions(instance_predictions, instances[i])\n",
    "            print('3:', instance_predictions, '\\n')\n",
    "\n",
    "            for prediction in instance_predictions:\n",
    "                len_scores = len(prediction[SCORE_IDX])\n",
    "                assert len_scores <= num_rankers\n",
    "                if len_scores < num_rankers:\n",
    "                    prediction[SCORE_IDX] = np.mean(\n",
    "                        prediction[SCORE_IDX] + (num_rankers - len_scores) * [FAKE_SCORE])\n",
    "                else:\n",
    "                    prediction[SCORE_IDX] = np.mean(prediction[SCORE_IDX])\n",
    "\n",
    "            instance_predictions = sorted(instance_predictions, key=itemgetter(SCORE_IDX), reverse=True)\n",
    "\n",
    "            if self.active:\n",
    "                instance_predictions = instance_predictions[:self.top_n]\n",
    "\n",
    "            for i in range(len(instance_predictions)):\n",
    "                instance_predictions[i][0] = i\n",
    "\n",
    "            all_data.append(instance_predictions)\n",
    "\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = EnsembleRanker(top_n=2, active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf: List[List[List[Union[Any]]]] = None,\n",
    "tfhub: List[List[List[Union[Any]]]] = None,\n",
    "rnet: List[List[List[Union[Any]]]] = None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_text_score_id_tfidf = [[[0,'haha', 1.1, 3], [1, 'lala', 0.9, 5], [2, 'jiujiu', 2.3, 1]],\n",
    "                            [[0, 'lala', 9.8, 5], [1, 'liu', 1.4, 6], [2, 'biubiu', 8.8, 9]]]\n",
    "rank_text_score_id_use = [[[0, 'liu', 12, 6], [1, 'miumiu', 0.8, 10], [2, 'jiujiu', 3.5, 1]],\n",
    "                          [[0, 'lala', 7.7, 5], [1, 'halala', 3, 2],[2, 'liu', 10, 6]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ([[0, 'haha', 0.4068496968004201, 3], [1, 'lala', 0.33287702465488916, 5], [2, 'jiujiu', 0.8506857296736056, 1]], [[0, 'liu', 12, 6], [1, 'miumiu', 0.8, 10], [2, 'jiujiu', 3.5, 1]]) \n",
      "\n",
      "2: ([[0, 'haha', [0.4068496968004201], 3], [1, 'lala', [0.33287702465488916], 5], [2, 'jiujiu', [0.8506857296736056], 1]], [[0, 'liu', 12, 6], [1, 'miumiu', 0.8, 10], [2, 'jiujiu', 3.5, 1]]) \n",
      "\n",
      "ins pred: [[0, 'haha', [0.4068496968004201], 3], [1, 'lala', [0.33287702465488916], 5], [2, 'jiujiu', [0.8506857296736056], 1]] \n",
      "\n",
      "3: [[0, 'haha', [0.4068496968004201], 3], [1, 'lala', [0.33287702465488916], 5], [2, 'jiujiu', [0.8506857296736056, 3.5], 1], [0, 'liu', [12], 6], [1, 'miumiu', [0.8], 10]] \n",
      "\n",
      "1: ([[0, 'lala', 0.7398808151391919, 5], [1, 'liu', 0.10569725930559883, 6], [2, 'biubiu', 0.6643827727780499, 9]], [[0, 'lala', 7.7, 5], [1, 'halala', 3, 2], [2, 'liu', 10, 6]]) \n",
      "\n",
      "2: ([[0, 'lala', [0.7398808151391919], 5], [1, 'liu', [0.10569725930559883], 6], [2, 'biubiu', [0.6643827727780499], 9]], [[0, 'lala', 7.7, 5], [1, 'halala', 3, 2], [2, 'liu', 10, 6]]) \n",
      "\n",
      "ins pred: [[0, 'lala', [0.7398808151391919], 5], [1, 'liu', [0.10569725930559883], 6], [2, 'biubiu', [0.6643827727780499], 9]] \n",
      "\n",
      "3: [[0, 'lala', [0.7398808151391919, 7.7], 5], [1, 'liu', [0.10569725930559883, 10], 6], [2, 'biubiu', [0.6643827727780499], 9], [1, 'halala', [3], 2]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[0, 'liu', 6.0005, 6], [1, 'jiujiu', 2.1753428648368027, 1]],\n",
       " [[0, 'liu', 5.052848629652799, 6], [1, 'lala', 4.219940407569596, 5]]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker(rank_text_score_id_tfidf, rank_text_score_id_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[0, 'haha', 1.1, 3], [1, 'lala', 0.9, 5], [2, 'jiujiu', 2.3, 1]],\n",
       "  [[0, 'liu', 12, 6], [1, 'miumiu', 0.8, 10], [2, 'jiujiu', 3.5, 1]]),\n",
       " ([[0, 'lala', 9.8, 5], [1, 'liu', 1.4, 6], [2, 'biubiu', 8.8, 9]],\n",
       "  [[0, 'lala', 7.7, 5], [1, 'halala', 3, 2], [2, 'liu', 10, 6]])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankers = [rank_text_score_id_tfidf, rank_text_score_id_use]\n",
    "list(zip(*rankers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73988082, 0.10569726, 0.66438277])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([x[2] for x in rank_text_score_id_tfidf[1]])\n",
    "arr/np.sqrt((arr**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.801/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10 + 1.4)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
