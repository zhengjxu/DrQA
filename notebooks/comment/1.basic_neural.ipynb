{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from deeppavlov.core.common.registry import register\n",
    "from deeppavlov.core.models.tf_model import TFModel\n",
    "from deeppavlov.core.common.log import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@register('ranker_encoder')\n",
    "class BasicNeuralRankerEncoder(TFModel):\n",
    "    def __init__(self, save_path=None, load_path=None, **kwargs):\n",
    "        self.hidden_size_dense_1 = 300\n",
    "        self.hidden_size_dense_2 = 300\n",
    "        self.hidden_size_dense_3 = 512\n",
    "        self.learning_rate = 0.01\n",
    "        self.question_pad_size = 3\n",
    "        self.context_pad_size = 40\n",
    "        self.emb_size = 512\n",
    "        self.n_epochs = 1000\n",
    "\n",
    "        # self.mode = kwargs.get('mode', None)\n",
    "\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            gpu_options=tf.GPUOptions(\n",
    "                allow_growth=True\n",
    "            )))\n",
    "        self._init_hub_modules()\n",
    "        self._init_graph()\n",
    "        self._init_optimizer()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        super().__init__(save_path=save_path, load_path=load_path)\n",
    "\n",
    "        # load model if exists:\n",
    "\n",
    "        if self.load_path is not None:\n",
    "            self.load()\n",
    "\n",
    "    def _init_hub_modules(self):\n",
    "        self.embedder = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "\n",
    "    def _init_graph(self):\n",
    "        self._init_placeholders()\n",
    "\n",
    "        batch_size = tf.shape(self.c_ph)[0]\n",
    "        # batch_size = 2\n",
    "        c_embs = tf.reshape(self.c_ph, [-1])  # reshape to 1 dimension\n",
    "        # q_embs = tf.reshape(self.q_ph, [-1])\n",
    "        c_embs = self.embedder(c_embs)        # convert to USE embedding\n",
    "        q_embs = self.embedder(self.q_ph)\n",
    "        # emb_size = tf.shape(c_embs)[1]\n",
    "\n",
    "        c_embs = tf.stack(c_embs)\n",
    "        q_embs = tf.stack(q_embs)\n",
    "        c_embs = tf.reshape(c_embs, shape=[batch_size, self.context_pad_size, self.emb_size])\n",
    "        # q_embs = tf.reshape(q_embs, shape=[batch_size, self.question_pad_size, self.emb_size])\n",
    "\n",
    "        # print(f\"c_embs shape: {c_embs}\")\n",
    "        # print(f\"q_embs shape: {q_embs}\")\n",
    "\n",
    "        q_mask = tf.sequence_mask(self.q_len_ph, maxlen=self.question_pad_size, dtype=tf.float32)\n",
    "        c_mask = tf.sequence_mask(self.c_len_ph, maxlen=self.context_pad_size, dtype=tf.float32)\n",
    "\n",
    "        q_mask = tf.expand_dims(q_mask, -1)\n",
    "        c_mask = tf.expand_dims(c_mask, -1)\n",
    "\n",
    "        # print(f\"q_mask shape: {q_mask}\")\n",
    "        # print(f\"c mask shape: {c_mask}\")\n",
    "\n",
    "        q_embs = tf.multiply(q_embs, q_mask)  # remove effect of padding\n",
    "        c_embs = tf.multiply(c_embs, c_mask)  \n",
    "\n",
    "        # print(\"Shapes after masking:\")\n",
    "        # print(f\"c_embs shape: {c_embs}\")\n",
    "        # print(f\"q_embs shape: {q_embs}\")\n",
    "\n",
    "        c_div = tf.expand_dims(tf.expand_dims(tf.cast(self.c_len_ph, dtype=tf.float32), -1), -1)\n",
    "        q_div = tf.expand_dims(tf.cast(self.q_len_ph, dtype=tf.float32), -1)\n",
    "\n",
    "        c_norm_emb = tf.reduce_sum(c_embs, axis=1, keepdims=True) / tf.sqrt(c_div)  # sum of emebdding divided by sqrt of length\n",
    "        q_norm_emb = tf.reduce_sum(q_embs, axis=0, keepdims=True) / tf.sqrt(q_div)\n",
    "\n",
    "        c_norm_emb = tf.squeeze(c_norm_emb)\n",
    "        # q_norm_emb = tf.squeeze(q_norm_emb)\n",
    "\n",
    "        # print(\"Normalized shapes: \")\n",
    "        # print(f\"c_norm shape: {c_norm_emb}\")\n",
    "        # print(f\"q_norm shape: {q_norm_emb}\")\n",
    "\n",
    "        # dense layer\n",
    "        dense_1 = tf.layers.dense(tf.reshape(c_norm_emb, [-1, self.emb_size]), units=self.hidden_size_dense_1,\n",
    "                                  activation=tf.tanh,\n",
    "                                  kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        dense_2 = tf.layers.dense(dense_1, units=self.hidden_size_dense_2, activation=tf.tanh,\n",
    "                                  kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        dense_3 = tf.layers.dense(dense_2, units=self.hidden_size_dense_3, activation=tf.tanh,\n",
    "                                  kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        # dot-product\n",
    "        dot_product = tf.squeeze(tf.matmul(q_norm_emb, tf.transpose(dense_3)))\n",
    "\n",
    "        # if self.mode == 'infer':\n",
    "        self.prob = tf.nn.softmax(logits=dot_product)\n",
    "\n",
    "        labels = tf.sequence_mask(1, maxlen=batch_size, dtype=tf.uint8)   # only the first chunck is correct answer\n",
    "\n",
    "        self.loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=dot_product, labels=labels))\n",
    "\n",
    "        self.sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "    def _init_placeholders(self):\n",
    "        self.c_ph = tf.placeholder(shape=(None, None), dtype=tf.string, name='c_ph')  # context placeholder\n",
    "        self.q_ph = tf.placeholder(shape=(None, ), dtype=tf.string, name='q_ph')      # question placeholder\n",
    "        self.c_len_ph = tf.placeholder(shape=(None, ), dtype=tf.uint8,\n",
    "                                       name='c_len_ph')\n",
    "        self.q_len_ph = tf.placeholder(shape=(), dtype=tf.uint8,\n",
    "                                       name='q_len_ph')\n",
    "\n",
    "    def _init_optimizer(self):\n",
    "        with tf.variable_scope('Optimizer'):\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(extra_update_ops):\n",
    "                opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "                grads_and_vars = opt.compute_gradients(self.loss)\n",
    "                self.train_op = opt.apply_gradients(grads_and_vars)\n",
    "\n",
    "        # self.train_op = tf.train.MomentumOptimizer(self.learning_rate, 0).minimize(self.loss)\n",
    "\n",
    "    def _build_feed_dict(self, inputs):\n",
    "        query = inputs[0]['question']  # 1 question string\n",
    "        chunk = inputs[0]['contexts']  # [context1, context2...]\n",
    "        chunk = [ch if isinstance(ch, str) else ch[1] for ch in chunk]  # [context1, context2...]\n",
    "        query = list(filter(lambda x: x != '', sent_tokenize(query)))   # [q_sent1, q_sent2,...]\n",
    "        chunk = [list(filter(lambda x: x != '', sent_tokenize(ch))) for ch in chunk]  # [[c1_sent1, c2_sent2...], [c2_sent1, c2_setn2...]...]  \n",
    "        q_len = len(query)\n",
    "        c_len = [len(el) for el in chunk]\n",
    "        q_pad = self._pad_sentences(query, self.question_pad_size) # padding \n",
    "        c_pad = self._pad_sentences(chunk, self.context_pad_size)\n",
    "        feed_dict = {self.q_ph: q_pad, self.c_ph: c_pad, self.q_len_ph: q_len, self.c_len_ph: c_len}\n",
    "        return feed_dict\n",
    "\n",
    "    def train_on_batch(self, inputs, *args, **kwargs):\n",
    "        feed_dict = self._build_feed_dict(inputs)\n",
    "        loss, _ = self.sess.run([self.loss, self.train_op], feed_dict)\n",
    "        return loss\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        feed_dict = self._build_feed_dict(inputs)\n",
    "        res = self.sess.run(self.prob, feed_dict)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def _pad_sentences(batch: Union[List[str], List[List[str]]], limit: int) -> Union[List[str], List[List[str]]]:\n",
    "        \"\"\"Pad a batch with empty string and cut batch if it exceeds the limit.\n",
    "\n",
    "        Args:\n",
    "            batch: data to be padded\n",
    "            limit: pad size in integer value\n",
    "\n",
    "        Returns:\n",
    "            padded data\n",
    "\n",
    "        \"\"\"\n",
    "        pad_batch = copy.deepcopy(batch)\n",
    "        if isinstance(batch[0], list):\n",
    "            for i in range(len(pad_batch)):\n",
    "                if len(pad_batch[i]) >= limit:\n",
    "                    pad_batch[i] = pad_batch[i][:limit]\n",
    "                else:\n",
    "                    pad_batch[i] += [''] * (limit - len(pad_batch[i]))\n",
    "        elif isinstance(batch[0], str):\n",
    "            if len(pad_batch) >= limit:\n",
    "                pad_batch = pad_batch[:limit]\n",
    "            else:\n",
    "                pad_batch += [''] * (limit - len(pad_batch))\n",
    "        return pad_batch\n",
    "\n",
    "# q = [\"Question 1?\", \"Sentence 2\"]\n",
    "# c = [[\"Doc 1 sentence 1.\", \"Doc second sentence second.\"],\n",
    "#      [\"Doc 2 sentence 1.\", \"Doc second sentence second.\", \"Third.\"]]\n",
    "# # y = [0, 1, 1]\n",
    "# encoder = BasicNeuralRankerEncoder()\n",
    "# prob = encoder(q, c)\n",
    "# print(prob)\n",
    "# _loss = encoder.train_on_batch(q, c)\n",
    "# print(_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
